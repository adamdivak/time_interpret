{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec0e8e1005ecd6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import pickle as pkl\n",
    "import os\n",
    "import numpy as np\n",
    "from tint.datasets import HMM, Mimic3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ad82ada67c5c4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define identical HMM definition as in the experiment\n",
    "# This will load the generated HMM data instead of re-generating the files (which take a long time)\n",
    "hmm = HMM(n_folds=5, fold=0, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa024841ebd9c7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# HMM - Get train and test input and output (x and y)\n",
    "hmm_test_data = hmm.preprocess(\"test\")\n",
    "hmm_test_x, hmm_test_y = hmm_test_data[\"x\"].numpy(), hmm_test_data[\"y\"].numpy()\n",
    "hmm_true_saliency = hmm.true_saliency(split=\"test\").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ffa3229eb02de",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Get test predictions from the classifier (y_hat)\n",
    "with open(\n",
    "    os.path.join(hmm.data_dir, \"classifier_predictions_test.npz\"), \"rb\"\n",
    ") as fp:\n",
    "    y_hat = pkl.load(file=fp).detach().numpy()\n",
    "    \n",
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e5fe6932c9764",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# MIMIC3 - Get train and test input and output (x and y)\n",
    "mimic3 = Mimic3(n_folds=5, fold=0, seed=42)\n",
    "\n",
    "_ = mimic3.preprocess(\"train\")\n",
    "mimic3_test_data = mimic3.preprocess(\"test\")\n",
    "mimic3_test_x, mimic3_test_y = mimic3_test_data[\"x\"].numpy(), mimic3_test_data[\"y\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e9d3c2b66ef36",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Get saved explanations by all explainers\n",
    "with open(\n",
    "    os.path.join(hmm.data_dir, \"hmm_saliency.npz\"), \"rb\"\n",
    ") as fp:\n",
    "    hmm_saliency = pkl.load(file=fp)\n",
    "    # try:\n",
    "    #     hmm_saliency = {k: v.detach().numpy() for k, v in hmm_saliency.items()}\n",
    "    # except Exception:\n",
    "    #     pass\n",
    "with open(\n",
    "    os.path.join(\"../experiments/mimic3/mortality/results/mimic3_saliency.npz\"), \"rb\"\n",
    ") as fp:\n",
    "    mimic3_saliency = pkl.load(file=fp)\n",
    "\n",
    "# Flip deletion extremal masks, so they have the same meaning as the preservation ones\n",
    "# No longer needed, we have added this to the code itself\n",
    "# if \"extremal_mask_deletion\" in hmm_saliency:\n",
    "#     hmm_saliency[\"extremal_mask_deletion\"] = 1 - hmm_saliency[\"extremal_mask_deletion\"]\n",
    "# if \"extremal_mask_deletion\" in mimic3_saliency:\n",
    "#     mimic3_saliency[\"extremal_mask_deletion\"] = 1 - mimic3_saliency[\"extremal_mask_deletion\"]\n",
    "\n",
    "print(hmm_saliency.keys())\n",
    "print(hmm_saliency[list(hmm_saliency.keys())[0]].shape)\n",
    "print(mimic3_saliency.keys())\n",
    "print(mimic3_saliency[list(mimic3_saliency.keys())[0]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae5ffe9f438b24",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load perturbed signals, saved in a separate file\n",
    "with open(\n",
    "    os.path.join(hmm.data_dir, \"x_test_perturbed_signals.npz\"), \"rb\"\n",
    ") as fp:\n",
    "    x_perturbed_signals_hmm = pkl.load(file=fp)\n",
    "with open(\n",
    "    os.path.join(\"../experiments/mimic3/mortality/results/mimic3_perturbed_signals.npz\"), \"rb\"\n",
    ") as fp:\n",
    "    x_perturbed_signals_mimic = pkl.load(file=fp)\n",
    "    \n",
    "print(x_perturbed_signals_hmm.keys())\n",
    "print(x_perturbed_signals_mimic.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee9b896f137fbd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# True vs explanation saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55015ee022d26163",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to create a single subplot\n",
    "def plot_saliency_subplot(ax, saliency, label, cmap, num_features=3):\n",
    "    saliency_img = ax.imshow(saliency, interpolation='nearest', cmap=cmap, aspect=\"auto\")\n",
    "    feature_values = np.arange(num_features)\n",
    "    ax.label_outer()\n",
    "    \n",
    "    ax.set_yticks([0, 1, 2])\n",
    "    ax.set_yticklabels(feature_values)\n",
    "    ax.set_yticks(feature_values[:-1] + 0.5, minor=True)\n",
    "    ax.grid(which='minor', alpha=0.8)\n",
    "    ax.grid(which='major', alpha=0.0)\n",
    "    ax.grid()\n",
    "    ax.set_ylabel(\"Feature\")\n",
    "    ax.set_title(label)\n",
    "    \n",
    "    return saliency_img\n",
    "\n",
    "def plot_saliency(explanation_methods, sample, save_fn=None):\n",
    "\n",
    "    # Light-dark blue colormap for the saliency maps\n",
    "    colors = [\"#004c6d\", \"#b5e2ff\"]\n",
    "    blues = LinearSegmentedColormap.from_list(\"blues\", colors, N=200)\n",
    "    \n",
    "    # Red-green colormap for the accurate/inaccurate classifier plot\n",
    "    colors = [\"xkcd:grapefruit\", \"palegreen\"]\n",
    "    red_green_cmap = LinearSegmentedColormap.from_list(\"red_green\", colors, N=2)\n",
    "    \n",
    "    subplot_rows = len(explanation_methods) + 2\n",
    "    fig, axs = plt.subplots(subplot_rows, 1, figsize=(6, (3 + len(explanation_methods))), layout='compressed')\n",
    "    # fig.suptitle(f\"Saliency for sample {sample}\")\n",
    "    \n",
    "    # Plot true saliency\n",
    "    img_true_saliency = plot_saliency_subplot(ax=axs[0], saliency=hmm_true_saliency[sample, :, :].T, label=\"True saliency\", cmap=blues)\n",
    "    \n",
    "    # Plot explained saliency per method\n",
    "    for (method, method_name), ax in zip(explanation_methods.items(), axs[1:-1]):\n",
    "        if method in hmm_saliency:\n",
    "            saliency = hmm_saliency[method]\n",
    "            plot_saliency_subplot(ax=ax, saliency=saliency[sample, :, :].T, label=method_name, cmap=blues)\n",
    "    \n",
    "    # Plot classifier accuracy\n",
    "    classifier_prediction_correct = (hmm_test_y[sample] == y_hat[sample]).astype(int).reshape(1, -1)\n",
    "    img_classifier_accuracy = axs[-1].imshow(classifier_prediction_correct, cmap=red_green_cmap, aspect=100)\n",
    "    \n",
    "    ratio = 10/200.0\n",
    "    xleft, xright = axs[-1].get_xlim()\n",
    "    ybottom, ytop = axs[-1].get_ylim()\n",
    "    axs[-1].set_aspect(abs((xright - xleft) / (ybottom - ytop)) * ratio)\n",
    "\n",
    "    axs[-1].set_yticks([])\n",
    "    axs[-1].set_title(\"Is classifier prediction correct\")\n",
    "    axs[-1].set_xlabel(\"Time\")\n",
    "    \n",
    "    # Add colorbars to the correct places\n",
    "    plt.colorbar(img_true_saliency, ax=axs[:-1], fraction=0.05, aspect=40, label=\"Saliency (mask) values\")\n",
    "    plt.colorbar(img_classifier_accuracy, ax=axs[-1], fraction=0.05, aspect=10, ticks=[0.25, 0.75], format=mpl.ticker.FixedFormatter([\"no\", \"yes\"]))\n",
    "    \n",
    "    if save_fn:\n",
    "        save_dir = os.path.dirname(save_fn)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        plt.savefig(save_fn)\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485acdf7fb84319e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# HMM sample to plot\n",
    "sample = 0\n",
    "\n",
    "# Explanation methods shown\n",
    "explanation_methods = {\n",
    "    \"extremal_mask_preservation\": \"Explanation saliency - ExtrMask (preservation)\", \n",
    "    \"extremal_mask_deletion\": \"Explanation saliency - ExtrMask (deletion, ours)\",\n",
    "}\n",
    "\n",
    "_ = plot_saliency(explanation_methods=explanation_methods, sample=sample, save_fn=f\"figures/true_explained_saliency.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277e93676696cbf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Explanation methods shown\n",
    "explanation_methods_all = {\n",
    "    \"deep_lift\": \"Explanation saliency - DeepLift\",\n",
    "    \"dyna_mask\": \"Explanation saliency - DynaMask\",\n",
    "    \"extremal_mask_preservation\": \"Explanation saliency - ExtrMask (preservation)\", \n",
    "    \"extremal_mask_deletion\": \"Explanation saliency - ExtrMask (deletion, ours)\",\n",
    "    # \"fit\": \"Explanation saliency - Fit\", # did not run correctly during generation\n",
    "    \"gradient_shap\": \"Explanation saliency - GradientShap\",\n",
    "    \"integrated_gradients\": \"Explanation saliency - IG\",\n",
    "    \"lime\": \"Explanation saliency - LIME\",\n",
    "    \"augmented_occlusion\": \"Explanation saliency - Aug Occ\",\n",
    "    \"occlusion\": \"Explanation saliency - Occlusion\",\n",
    "    \"retain\": \"Explanation saliency - Retain\",\n",
    "}\n",
    "\n",
    "_ = plot_saliency(explanation_methods=explanation_methods_all, sample=sample, save_fn=f\"figures/true_explained_saliency_all_methods.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e837ee3b1c2240",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sample = 0\n",
    "\n",
    "experiments = [\"hmm\", \"mimic\"]\n",
    "explanation_methods = {\n",
    "    \"extremal_mask_preservation\": \"ExtrMask (preservation)\", \n",
    "    \"extremal_mask_deletion\": \"ExtrMask (deletion, ours)\"\n",
    "}\n",
    "\n",
    "# itertools.batched is only available in Python 3.12\n",
    "def batched(iterable, n):\n",
    "    # batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    it = iter(iterable)\n",
    "    while batch := tuple(itertools.islice(it, n)):\n",
    "        yield batch\n",
    "\n",
    "def plot_perturbation(input_signals, perturbed_signal, saliency, num_features, method, method_name, max_features_per_row=6):\n",
    "    all_feature_ids = range(0, num_features)\n",
    "    figs = []\n",
    "    for group_id, feature_ids in enumerate(list(batched(all_feature_ids, max_features_per_row))):\n",
    "        base_ax = None\n",
    "        base_mask_ax = None\n",
    "        \n",
    "        num_features = len(feature_ids)\n",
    "        fig, axs = plt.subplots(4, num_features, figsize=(3 * num_features, 6), layout='compressed')\n",
    "        \n",
    "        for feature_id, ax_group in zip(feature_ids, axs.T):\n",
    "            add_y_axis = feature_id == 0\n",
    "            ax_x, ax_perturbed_signal, ax_perturbed_signal_diff, ax_saliency = ax_group[0], ax_group[1], ax_group[2], ax_group[3]\n",
    "            if base_ax is None:\n",
    "                base_ax = ax_x\n",
    "            if base_mask_ax is None:\n",
    "                base_mask_ax = ax_saliency\n",
    "    \n",
    "            ax_x.plot(input_signals[sample, :, feature_id], label=f\"x{feature_id}\")\n",
    "            ax_x.sharey(base_ax)\n",
    "            ax_x.set_title(f\"Original signal - feature {feature_id}\")\n",
    "            ax_x.set_xlabel(f\"Time\")\n",
    "            ax_x.label_outer()\n",
    "    \n",
    "            ax_perturbed_signal.plot(perturbed_signal[sample, :, feature_id])\n",
    "            ax_perturbed_signal.set_title(f\"Perturbed signal\")\n",
    "            ax_perturbed_signal.sharey(base_ax)\n",
    "            ax_perturbed_signal.set_xlabel(f\"Time\")\n",
    "            ax_perturbed_signal.label_outer() # set labels on the first plot only\n",
    "            \n",
    "            ax_perturbed_signal_diff.plot(input_signals[sample, :, feature_id] - perturbed_signal[sample, :, feature_id])\n",
    "            ax_perturbed_signal_diff.set_title(f\"Difference of original\\nand perturbed signal\")\n",
    "            ax_perturbed_signal_diff.sharey(base_ax)\n",
    "            ax_perturbed_signal_diff.set_xlabel(f\"Time\")\n",
    "            ax_perturbed_signal_diff.label_outer() # set labels on the first plot only\n",
    "            \n",
    "            ax_saliency.plot(saliency[sample, :, feature_id])\n",
    "            ax_saliency.set_title(f\"Saliency\")\n",
    "            ax_saliency.sharey(base_mask_ax)\n",
    "            ax_saliency.set_xlabel(f\"Time\")\n",
    "            ax_saliency.label_outer()\n",
    "        \n",
    "        # fig.suptitle(f\"{experiment} {method_name} {sample} input signals, masks and perturbed signals\")\n",
    "        os.makedirs(\"figures\", exist_ok=True)\n",
    "        plt.savefig(f\"figures/{experiment}_{method}_{sample}_inputs_masks_perturbations_{group_id}.svg\")\n",
    "        \n",
    "        figs.append(fig)\n",
    "    return figs\n",
    "    \n",
    "for experiment in experiments:\n",
    "    if experiment == \"hmm\":\n",
    "        input_signals = hmm_test_x\n",
    "        perturbed_signals = x_perturbed_signals_hmm\n",
    "        saliencies = hmm_saliency\n",
    "        num_features = 3\n",
    "    elif experiment == \"mimic\":\n",
    "        input_signals = mimic3_test_x\n",
    "        perturbed_signals = x_perturbed_signals_mimic\n",
    "        saliencies = mimic3_saliency\n",
    "        num_features = 30\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized experiment {experiment}\")\n",
    "    \n",
    "    for method, method_name in explanation_methods.items():\n",
    "        saliency = saliencies[method]\n",
    "        perturbed_signal = perturbed_signals[method]\n",
    "        \n",
    "        figs = plot_perturbation(input_signals, perturbed_signal, saliency, num_features, method, method_name)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3db026c86003b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
